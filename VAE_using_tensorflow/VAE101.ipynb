{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE TO IMITATE MNIST\n",
    "https://github.com/FelixMohr/Deep-learning-with-Python/blob/master/VAE.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ..\\data\\MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ..\\data\\MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ..\\data\\MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ..\\data\\MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('..\\data\\MNIST_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholders\n",
    "X_ph = tf.placeholder(\n",
    "            dtype = tf.float32,\n",
    "            shape = [None, 28, 28, 1],\n",
    "            name = \"conv_in\"\n",
    "        )\n",
    "Y_ph = tf.placeholder(dtype=tf.float32,\n",
    "                      shape = [None, 28, 28],\n",
    "                      name = 'Y')\n",
    "\n",
    "Y_flat_ph = tf.reshape(Y_ph,\n",
    "                       shape = [-1, 28*28])\n",
    "\n",
    "keep_prob_ph = tf.placeholder(dtype = tf.float32,\n",
    "                              shape = (),\n",
    "                              name = 'keep_prob')\n",
    "dec_in_channels = 1\n",
    "n_latent = 8\n",
    "reshaped_dim = [-1,7,7,dec_in_channels]\n",
    "inputs_decoder = int(49*dec_in_channels/2)\n",
    "\n",
    "def lrelu(x, alpha = 0.03):\n",
    "    return tf.maximum(x, tf.multiply(x, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder\n",
    "image to mean and stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_backup(X_in, keep_prob):\n",
    "    activation = lrelu\n",
    "    with tf.variable_scope(\"encoder\",reuse = None):\n",
    "        X = tf.reshape(X_in, shape = [-1, 28, 28, 1])\n",
    "        x = tf.layers.conv2d(X,\n",
    "                             filters = 64,\n",
    "                             kernel_size = 4,\n",
    "                             strides = 2,\n",
    "                             padding = same,\n",
    "                             activation = activation\n",
    "                            )\n",
    "        x = tf.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d(X,\n",
    "                     filters = 64,\n",
    "                     kernel_size = 4,\n",
    "                     strides = 2,\n",
    "                     padding = same,\n",
    "                     activation = activation\n",
    "                    )\n",
    "        x = tf.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d(X,\n",
    "                     filters = 64,\n",
    "                     kernel_size = 4,\n",
    "                     strides = 1,\n",
    "                     padding = same,\n",
    "                     activation = activation\n",
    "                    )\n",
    "        x = tf.dropout(x, keep_prob)\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        mn = tf.layers.dense(x, units = n_latent)\n",
    "        epsilon = tf.random_normal(tf.stack([tf.shape(x)[0], n_latent]))\n",
    "        sd = .5*tf.layers.dense(x, units = n_latent)\n",
    "        z = mn+tf.multiply(epsilon,tf.exp(sd))\n",
    "        \n",
    "        return z,mn,sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "def encoder(in_sample,keep_prob = 1,tracking = False):\n",
    "    if tracking:\n",
    "        X_in = tf.placeholder(\n",
    "            dtype = tf.float32,\n",
    "            shape = [None, 28, 28, 1],\n",
    "            name = \"conv_in\"\n",
    "        )\n",
    "    else:\n",
    "        X_in = in_sample\n",
    "    activation = lrelu\n",
    "    with tf.variable_scope(\"encoder\",reuse = None):\n",
    "        X = tf.reshape(X_in, shape = [-1, 28, 28, 1])  # [3,28,28,1]\n",
    "        conv1 = tf.layers.conv2d(X,                    # [3,14,14,64]\n",
    "                             filters = 64,\n",
    "                             kernel_size = 4,\n",
    "                             strides = 2,\n",
    "                             padding = 'same',\n",
    "                             activation = activation\n",
    "                            )\n",
    "        dropout1 = tf.nn.dropout(conv1, keep_prob)\n",
    "        conv2 = tf.layers.conv2d(dropout1,             # [3,7,7,64]\n",
    "                     filters = 64,\n",
    "                     kernel_size = 4,\n",
    "                     strides = 2,\n",
    "                     padding = 'same',\n",
    "                     activation = activation\n",
    "                    )\n",
    "        dropout2 = tf.nn.dropout(conv2, keep_prob)     \n",
    "        conv3 = tf.layers.conv2d(dropout2,             # [3,7,7,64]\n",
    "                     filters = 64,\n",
    "                     kernel_size = 4,\n",
    "                     strides = 1,\n",
    "                     padding = 'same',\n",
    "                     activation = activation\n",
    "                    )\n",
    "        dropout3 = tf.nn.dropout(conv3, keep_prob)\n",
    "        flatten = tf.contrib.layers.flatten(dropout3)  # [3,3136]\n",
    "        mn = tf.layers.dense(flatten, units = n_latent)                        # [3,8]\n",
    "        epsilon = tf.random_normal(tf.stack([tf.shape(flatten)[0], n_latent])) # [3,8]\n",
    "        sd = .5*tf.layers.dense(flatten, units = n_latent)                     # [3,8]\n",
    "        z = mn+tf.multiply(epsilon,tf.exp(sd))                                 # [3,8]\n",
    "        if tracking:\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth=True\n",
    "            sess = tf.Session(config=config)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(epsilon, feed_dict =\n",
    "                            {X_in: in_sample})\n",
    "        return z,mn,sd\n",
    "\n",
    "image_sample = np.ones((3,28,28,1))\n",
    "print(encoder(image_sample,1,True).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "def decoder(sampled_z_in, keep_prob,tracking = False):\n",
    "    activation = lrelu\n",
    "    if tracking:\n",
    "         sampled_z = tf.placeholder(\n",
    "             dtype = tf.float32,\n",
    "             shape = [None, 8],\n",
    "             name = \"conv_in\"\n",
    "         )\n",
    "    else:\n",
    "        sampled_z = sampled_z_in\n",
    "    with tf.variable_scope(\"decoder\", reuse = None):\n",
    "        x = tf.layers.dense(sampled_z, units = inputs_decoder, activation = lrelu) # [3,24]\n",
    "        x2 = tf.layers.dense(x, units = inputs_decoder*2+1, activation = lrelu)    # [3,49]\n",
    "        unflatten = tf.reshape(x2, reshaped_dim)                                   # [3,7,7,1]\n",
    "        deconv_3 = tf.layers.conv2d_transpose(unflatten,                           # [3,7,7,64]\n",
    "                                              filters = 64,\n",
    "                                              kernel_size = 4,\n",
    "                                              strides = 1,\n",
    "                                              padding = 'same'\n",
    "                                             )\n",
    "        dropout_3 = tf.nn.dropout(deconv_3, keep_prob)\n",
    "        deconv_2 = tf.layers.conv2d_transpose(dropout_3,                           # [3,14,14,64]\n",
    "                                              filters = 64,\n",
    "                                              kernel_size = 4,\n",
    "                                              strides = 2,\n",
    "                                              padding = 'same'\n",
    "                                             )\n",
    "        dropout_2 = tf.nn.dropout(deconv_2, keep_prob)\n",
    "        deconv_1 = tf.layers.conv2d_transpose(dropout_2,                           # [3,28,28,64]\n",
    "                                              filters = 64,\n",
    "                                              kernel_size = 4,\n",
    "                                              strides = 2,\n",
    "                                              padding = 'same'\n",
    "                                             )\n",
    "        dropout_1 = tf.nn.dropout(deconv_1, keep_prob)                             # [3,50176]\n",
    "        flatten = tf.contrib.layers.flatten(dropout_1)\n",
    "        decode_out = tf.layers.dense(flatten, units = 28*28, activation = tf.nn.sigmoid) # [3,784]\n",
    "        img = tf.reshape(decode_out, shape = [-1,28,28,1])                         # [3,28,28,1]\n",
    "        if tracking:\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth=True\n",
    "            sess = tf.Session(config=config)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(img, feed_dict =\n",
    "                            {sampled_z: sampled_z_in})\n",
    "        return img\n",
    "sample_z = np.ones((3,8))\n",
    "print(decoder(sample_z,1,True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define & compute loss function\n",
    "loss = combineation of KL divergence &  squared difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "with tf.variable_scope(\"loss\", reuse = True):\n",
    "    sampled, mn, sd = encoder(X_ph, keep_prob_ph)\n",
    "    dec = decoder(sampled, keep_prob_ph)\n",
    "    \n",
    "    unreshaped = tf.reshape(dec, [-1,28*28])\n",
    "    img_loss = tf.reduce_sum = (tf.squared_difference(unreshaped, Y_flat_ph), 1)\n",
    "    latent_loss = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
