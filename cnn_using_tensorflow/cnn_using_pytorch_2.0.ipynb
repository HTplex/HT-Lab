{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pytorch, data already in torchvision\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request as url\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "CIFAR already downloaded by tensorflow part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_batch_1', 'data_batch_4', 'data_batch_3', 'data_batch_2', 'data_batch_5']\n",
      "(49000, 3072) (49000,)\n",
      "(1000, 3072) (1000,)\n",
      "(10000, 3072) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import _pickle as pickle\n",
    "def load_data():\n",
    "    if not os.path.exists('.././data/cifar-10-python.tar.gz'):\n",
    "        download_data()\n",
    "    if not os.path.exists('.././data/cifar-10-batches-py/'):\n",
    "        print(\"extracting...\")\n",
    "        package = tarfile.open('.././data/cifar-10-python.tar.gz')\n",
    "        package.extractall('.././data')\n",
    "        package.close()\n",
    "        \n",
    "    root_dir = os.getcwd()\n",
    "    os.chdir('.././data/cifar-10-batches-py')\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    data_train = glob.glob('data_batch*')\n",
    "    print(data_train)\n",
    "    #try:\n",
    "    for name in data_train:\n",
    "        handle = open(name, 'rb')\n",
    "        cmap = pickle.load(handle, encoding='bytes')\n",
    "        train_data.append(cmap[b'data'])\n",
    "        train_label.append(cmap[b'labels'])\n",
    "        handle.close()\n",
    "    # Turn the dataset into numpy compatible arrays.\n",
    "    train_data = np.concatenate(train_data, axis=0)\n",
    "    train_label = np.concatenate(train_label)\n",
    "    handle = open('test_batch', 'rb')\n",
    "    cmap = pickle.load(handle, encoding='bytes')\n",
    "    test_data.append(cmap[b'data'])\n",
    "    test_label.append(cmap[b'labels'])\n",
    "    test_data = np.array(test_data[0])\n",
    "    test_label = np.array(test_label[0])\n",
    "    #except BaseException:\n",
    "#         os.chdir(root_dir)\n",
    "#         print('Something went wrong...')\n",
    "#         return None\n",
    "    os.chdir(root_dir)\n",
    "    return train_data,train_label,test_data,test_label\n",
    "\n",
    "train_data,train_label,test_data,test_label = load_data()\n",
    "val_size = 1000\n",
    "val_data = train_data[-1000:]\n",
    "val_label = train_label[-1000:]\n",
    "train_data = train_data[:-1000]\n",
    "train_label = train_label [:-1000]\n",
    "print(train_data.shape, train_label.shape)\n",
    "print(val_data.shape, val_label.shape)\n",
    "print(test_data.shape, test_label.shape)\n",
    "\n",
    "train_data = train_data/255.\n",
    "val_data = val_data/255.\n",
    "test_data = test_data/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build net\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16,64,5)\n",
    "        self.fc1 = nn.Linear(64*5*5,328)\n",
    "        self.fc2 = nn.Linear(328,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = func.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = func.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64*5*5)\n",
    "        x = self.fc1(x)\n",
    "        x = func.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = func.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss func\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 3, 32, 32)\n",
      "Variable containing:\n",
      " 0.0647 -0.0302  0.0432  0.0514  0.0073 -0.0323 -0.0982  0.0084  0.0553 -0.0184\n",
      " 0.0754 -0.0297  0.0398  0.0364 -0.0021 -0.0290 -0.1099  0.0219  0.0729 -0.0052\n",
      "[torch.cuda.FloatTensor of size 2x10 (GPU 0)]\n",
      "\n",
      "[[6 9 9 ..., 4 9 3]]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "(10000, 3, 32, 32)\n",
      "Variable containing:\n",
      " 0.0767 -0.0394  0.0436  0.0435 -0.0009 -0.0263 -0.1055  0.0114  0.0606 -0.0118\n",
      " 0.0785 -0.0336  0.0332  0.0311 -0.0044 -0.0303 -0.1124  0.0176  0.0777  0.0007\n",
      "[torch.cuda.FloatTensor of size 2x10 (GPU 0)]\n",
      "\n",
      "[[3 8 8 ..., 5 1 7]]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "train_data_r = train_data.reshape([-1,3,32,32])\n",
    "# train_data_r = train_data_r.transpose([0,3,1,2])\n",
    "train_data_r = train_data_r.astype(np.float32)\n",
    "print(train_data_r.shape)\n",
    "feed_data = Variable(torch.from_numpy(train_data_r[0:2]).cuda())\n",
    "# print(feed_data)\n",
    "print(net(feed_data))\n",
    "\n",
    "print(train_label.reshape([1,train_label.shape[0]]))\n",
    "train_label_h = np.zeros((train_label.shape[0],10))\n",
    "train_label_h[np.arange(train_label.shape[0]), train_label] = 1\n",
    "print(train_label_h[0])\n",
    "\n",
    "train_label_r = train_label.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "test_data_r = test_data.reshape([-1,3,32,32])\n",
    "# train_data_r = train_data_r.transpose([0,3,1,2])\n",
    "test_data_r = test_data_r.astype(np.float32)\n",
    "print(test_data_r.shape)\n",
    "feed_data = Variable(torch.from_numpy(test_data_r[0:2]).cuda())\n",
    "# print(feed_data)\n",
    "print(net(feed_data))\n",
    "\n",
    "print(test_label.reshape([1,test_label.shape[0]]))\n",
    "test_label_h = np.zeros((test_label.shape[0],10))\n",
    "test_label_h[np.arange(test_label.shape[0]), test_label] = 1\n",
    "print(test_label_h[0])\n",
    "\n",
    "test_label_r = test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f610699def0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60f01c1898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "samp = train_data[0].reshape([3,32,32])\n",
    "# samp = samp[0,:,:]\n",
    "#samp2 = train_data[0].reshape([32,32,3])\n",
    "samp = samp.transpose([1,2,0])\n",
    "plt.matshow(samp[:,:,0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 63 %\n",
      "[1,  9901] loss: 0.045\n",
      "[1, 19901] loss: 0.047\n",
      "[1, 29901] loss: 0.045\n",
      "[1, 39901] loss: 0.047\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[2,  9901] loss: 0.044\n",
      "[2, 19901] loss: 0.046\n",
      "[2, 29901] loss: 0.044\n",
      "[2, 39901] loss: 0.046\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[3,  9901] loss: 0.043\n",
      "[3, 19901] loss: 0.044\n",
      "[3, 29901] loss: 0.043\n",
      "[3, 39901] loss: 0.045\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[4,  9901] loss: 0.042\n",
      "[4, 19901] loss: 0.043\n",
      "[4, 29901] loss: 0.042\n",
      "[4, 39901] loss: 0.044\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[5,  9901] loss: 0.041\n",
      "[5, 19901] loss: 0.042\n",
      "[5, 29901] loss: 0.041\n",
      "[5, 39901] loss: 0.043\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[6,  9901] loss: 0.040\n",
      "[6, 19901] loss: 0.041\n",
      "[6, 29901] loss: 0.040\n",
      "[6, 39901] loss: 0.042\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[7,  9901] loss: 0.039\n",
      "[7, 19901] loss: 0.040\n",
      "[7, 29901] loss: 0.039\n",
      "[7, 39901] loss: 0.041\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[8,  9901] loss: 0.038\n",
      "[8, 19901] loss: 0.039\n",
      "[8, 29901] loss: 0.038\n",
      "[8, 39901] loss: 0.040\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[9,  9901] loss: 0.037\n",
      "[9, 19901] loss: 0.038\n",
      "[9, 29901] loss: 0.037\n",
      "[9, 39901] loss: 0.039\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[10,  9901] loss: 0.036\n",
      "[10, 19901] loss: 0.037\n",
      "[10, 29901] loss: 0.036\n",
      "[10, 39901] loss: 0.038\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[11,  9901] loss: 0.035\n",
      "[11, 19901] loss: 0.036\n",
      "[11, 29901] loss: 0.035\n",
      "[11, 39901] loss: 0.036\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[12,  9901] loss: 0.034\n",
      "[12, 19901] loss: 0.035\n",
      "[12, 29901] loss: 0.034\n",
      "[12, 39901] loss: 0.035\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[13,  9901] loss: 0.034\n",
      "[13, 19901] loss: 0.034\n",
      "[13, 29901] loss: 0.033\n",
      "[13, 39901] loss: 0.034\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[14,  9901] loss: 0.033\n",
      "[14, 19901] loss: 0.033\n",
      "[14, 29901] loss: 0.032\n",
      "[14, 39901] loss: 0.033\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[15,  9901] loss: 0.032\n",
      "[15, 19901] loss: 0.032\n",
      "[15, 29901] loss: 0.031\n",
      "[15, 39901] loss: 0.032\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[16,  9901] loss: 0.031\n",
      "[16, 19901] loss: 0.031\n",
      "[16, 29901] loss: 0.030\n",
      "[16, 39901] loss: 0.031\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[17,  9901] loss: 0.030\n",
      "[17, 19901] loss: 0.030\n",
      "[17, 29901] loss: 0.029\n",
      "[17, 39901] loss: 0.030\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[18,  9901] loss: 0.029\n",
      "[18, 19901] loss: 0.029\n",
      "[18, 29901] loss: 0.028\n",
      "[18, 39901] loss: 0.029\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[19,  9901] loss: 0.028\n",
      "[19, 19901] loss: 0.028\n",
      "[19, 29901] loss: 0.027\n",
      "[19, 39901] loss: 0.028\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[20,  9901] loss: 0.027\n",
      "[20, 19901] loss: 0.027\n",
      "[20, 29901] loss: 0.027\n",
      "[20, 39901] loss: 0.027\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[21,  9901] loss: 0.027\n",
      "[21, 19901] loss: 0.026\n",
      "[21, 29901] loss: 0.026\n",
      "[21, 39901] loss: 0.027\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[22,  9901] loss: 0.026\n",
      "[22, 19901] loss: 0.026\n",
      "[22, 29901] loss: 0.025\n",
      "[22, 39901] loss: 0.026\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[23,  9901] loss: 0.025\n",
      "[23, 19901] loss: 0.025\n",
      "[23, 29901] loss: 0.025\n",
      "[23, 39901] loss: 0.025\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[24,  9901] loss: 0.023\n",
      "[24, 19901] loss: 0.024\n",
      "[24, 29901] loss: 0.024\n",
      "[24, 39901] loss: 0.024\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[25,  9901] loss: 0.022\n",
      "[25, 19901] loss: 0.023\n",
      "[25, 29901] loss: 0.024\n",
      "[25, 39901] loss: 0.023\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[26,  9901] loss: 0.021\n",
      "[26, 19901] loss: 0.023\n",
      "[26, 29901] loss: 0.023\n",
      "[26, 39901] loss: 0.022\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[27,  9901] loss: 0.020\n",
      "[27, 19901] loss: 0.023\n",
      "[27, 29901] loss: 0.022\n",
      "[27, 39901] loss: 0.021\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[28,  9901] loss: 0.020\n",
      "[28, 19901] loss: 0.022\n",
      "[28, 29901] loss: 0.020\n",
      "[28, 39901] loss: 0.020\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[29,  9901] loss: 0.020\n",
      "[29, 19901] loss: 0.021\n",
      "[29, 29901] loss: 0.019\n",
      "[29, 39901] loss: 0.019\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[30,  9901] loss: 0.019\n",
      "[30, 19901] loss: 0.019\n",
      "[30, 29901] loss: 0.018\n",
      "[30, 39901] loss: 0.018\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[31,  9901] loss: 0.017\n",
      "[31, 19901] loss: 0.018\n",
      "[31, 29901] loss: 0.016\n",
      "[31, 39901] loss: 0.017\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[32,  9901] loss: 0.016\n",
      "[32, 19901] loss: 0.016\n",
      "[32, 29901] loss: 0.015\n",
      "[32, 39901] loss: 0.016\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[33,  9901] loss: 0.015\n",
      "[33, 19901] loss: 0.015\n",
      "[33, 29901] loss: 0.015\n",
      "[33, 39901] loss: 0.016\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "[34,  9901] loss: 0.015\n",
      "[34, 19901] loss: 0.015\n",
      "[34, 29901] loss: 0.014\n",
      "[34, 39901] loss: 0.016\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[35,  9901] loss: 0.015\n",
      "[35, 19901] loss: 0.014\n",
      "[35, 29901] loss: 0.015\n",
      "[35, 39901] loss: 0.016\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[36,  9901] loss: 0.015\n",
      "[36, 19901] loss: 0.015\n",
      "[36, 29901] loss: 0.015\n",
      "[36, 39901] loss: 0.016\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[37,  9901] loss: 0.015\n",
      "[37, 19901] loss: 0.014\n",
      "[37, 29901] loss: 0.015\n",
      "[37, 39901] loss: 0.015\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[38,  9901] loss: 0.016\n",
      "[38, 19901] loss: 0.014\n",
      "[38, 29901] loss: 0.014\n",
      "[38, 39901] loss: 0.014\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[39,  9901] loss: 0.015\n",
      "[39, 19901] loss: 0.014\n",
      "[39, 29901] loss: 0.013\n",
      "[39, 39901] loss: 0.013\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[40,  9901] loss: 0.014\n",
      "[40, 19901] loss: 0.013\n",
      "[40, 29901] loss: 0.012\n",
      "[40, 39901] loss: 0.013\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[41,  9901] loss: 0.013\n",
      "[41, 19901] loss: 0.012\n",
      "[41, 29901] loss: 0.013\n",
      "[41, 39901] loss: 0.012\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[42,  9901] loss: 0.012\n",
      "[42, 19901] loss: 0.012\n",
      "[42, 29901] loss: 0.012\n",
      "[42, 39901] loss: 0.011\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[43,  9901] loss: 0.012\n",
      "[43, 19901] loss: 0.012\n",
      "[43, 29901] loss: 0.012\n",
      "[43, 39901] loss: 0.011\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[44,  9901] loss: 0.011\n",
      "[44, 19901] loss: 0.012\n",
      "[44, 29901] loss: 0.012\n",
      "[44, 39901] loss: 0.010\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[45,  9901] loss: 0.010\n",
      "[45, 19901] loss: 0.011\n",
      "[45, 29901] loss: 0.012\n",
      "[45, 39901] loss: 0.010\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "[46,  9901] loss: 0.010\n",
      "[46, 19901] loss: 0.011\n",
      "[46, 29901] loss: 0.011\n",
      "[46, 39901] loss: 0.009\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[47,  9901] loss: 0.009\n",
      "[47, 19901] loss: 0.011\n",
      "[47, 29901] loss: 0.010\n",
      "[47, 39901] loss: 0.008\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "[48,  9901] loss: 0.009\n",
      "[48, 19901] loss: 0.010\n",
      "[48, 29901] loss: 0.008\n",
      "[48, 39901] loss: 0.007\n",
      "Accuracy of the network on the 10000 test images: 65 %\n",
      "[49,  9901] loss: 0.008\n",
      "[49, 19901] loss: 0.008\n",
      "[49, 29901] loss: 0.008\n",
      "[49, 39901] loss: 0.006\n",
      "Accuracy of the network on the 10000 test images: 66 %\n",
      "[50,  9901] loss: 0.008\n",
      "[50, 19901] loss: 0.008\n",
      "[50, 29901] loss: 0.006\n",
      "[50, 39901] loss: 0.005\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for i in np.arange(0,train_data.shape[0]-batch_size,batch_size):\n",
    "        inputs = torch.from_numpy(train_data_r[i:i+batch_size])\n",
    "        labels = torch.from_numpy(train_label_r[i:i+batch_size]).type(torch.LongTensor)\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        if i/batch_size % 100 == 99:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        if i == 0:\n",
    "            val_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 65 %\n"
     ]
    }
   ],
   "source": [
    "def val_acc():\n",
    "    correct = 0\n",
    "    total = test_data.shape[0]\n",
    "    #for i in np.arange(test_data.shape[0]):\n",
    "    images = torch.from_numpy(test_data_r)\n",
    "    labels = test_label\n",
    "    images = Variable(images.cuda())\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    # return predicted\n",
    "    correct += np.sum(Variable(predicted).data.cpu().numpy()\n",
    "                      == labels)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "m = val_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
